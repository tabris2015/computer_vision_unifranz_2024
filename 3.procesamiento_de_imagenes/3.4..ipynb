{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación de perspectiva\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación afín\n",
    "\n",
    "En una transformación afín, todas las líneas paralelas en la imagen original se mantienen paralelas en la imagen transformada. Para definir una matriz de transformación afín, se necesitan tres puntos en la imagen original y los correspondientes tres puntos en la imagen transformada. Con esto, se puede usar la función `getAffineTransform` para obtener una matriz de transformación que se puede usar en la función `warpAffine`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [14, 8]    # incrementar tamaño de plots\n",
    "\n",
    "def display2(img1, img2):\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Filtrada\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"affine.png\")\n",
    "\n",
    "filas, cols, ch = img.shape\n",
    "\n",
    "pts1 = np.float32([[50, 50], [200, 50], [50, 200]])\n",
    "pts2 = np.float32([[10, 100], [200, 50], [100, 250]])\n",
    "\n",
    "M = cv2.getAffineTransform(pts1, pts2)\n",
    "print(M)\n",
    "\n",
    "img_tr = cv2.warpAffine(img, M, (cols, filas))\n",
    "\n",
    "display2(img, img_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de perspectiva\n",
    "Para una transformación de perspectiva, se necesita una matriz de transformación de dimensiones 3x3. Las líneas rectas en la imagen original se mantendrán como líneas rectas en la imagen transformada. Para poder encontrar esta transformación, se necesita definir **4 puntos** en ambas imágenes. Es importante considerar que de los 4 puntos, 3 de ellos no deben ser colineales. La matriz de transformación se puede hallar usando la función `getPerspectiveTransform`. Y luego aplicar la transformacion con la funcion `warpPerspective`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"sudoku_perspective.png\")\n",
    "filas, cols, ch = img.shape\n",
    "\n",
    "\n",
    "pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "print(M)\n",
    "img_tr = cv2.warpPerspective(img,M,(300,300))\n",
    "\n",
    "display2(img, img_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Transformar la perspectiva de las siguientes imágenes:\n",
    "\n",
    "![parking](parking.jpg)\n",
    "\n",
    "![parking2](parking2.jpg)\n",
    "\n",
    "Para la siguiente imagen, además de transformar la perspectiva, también rotar la imagen para que se pueda leer el texto:\n",
    "\n",
    "\n",
    "![parking3](parking3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking = cv2.imread(\"parking3.jpg\")\n",
    "pts1 = np.float32([[115, 45],[290,45],[90, 70],[330,70]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "print(parking.shape)\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "print(M)\n",
    "img_tr = cv2.warpPerspective(parking,M,(300,300))\n",
    "theta = 180\n",
    "#                           (centro x      , centro y        , theta, escala)\n",
    "M_r = cv2.getRotationMatrix2D(((300 - 1) / 2, (300 - 1) / 2), theta, 1)\n",
    "#                     (img, matriz, size) \n",
    "img_final = cv2.warpAffine(img_tr, M_r, (300, 300))\n",
    "display2(parking, img_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gray_row(*imgs):\n",
    "    for i, img in enumerate(imgs):\n",
    "        plt.subplot(1, len(imgs), i + 1)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.title(f\"{i}\")\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blur = cv2.GaussianBlur(cv2.cvtColor(img_final, cv2.COLOR_BGR2GRAY), (5, 5), 0)\n",
    "res, th3 = cv2.threshold(img_blur, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "display_gray_row(img_final,th3)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62eb3e910e44ea0e9978ea29c6f3fc7540fb99bfa181faf1a80d42ed442aa249"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('unifranz': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
